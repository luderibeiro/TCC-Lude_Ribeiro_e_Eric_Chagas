\chapter[Referencial Teórico]{Referencial Teórico}
\label{chapter:Referencial_Teorico}

Este capítulo estabelece os fundamentos teóricos que sustentam a investigação. A discussão inicia-se com a arquitetura dos Grandes Modelos de Linguagem (LLMs), detalhando o mecanismo de atenção que permite a compreensão de contexto em código. Em seguida, justifica-se a seleção das ferramentas (Copilot e ChatGPT) com base em sua penetração de mercado e capacidades técnicas.

O núcleo deste referencial aprofunda-se nos conceitos de Qualidade de Software, definindo as métricas estáticas (Ciclomática, Cognitiva e Dívida Técnica) com base em seus autores seminais (McCabe, Cunningham). Por fim, discute-se o estado da arte sobre os impactos da IA na engenharia de software, contrapondo os ganhos de velocidade com os riscos de degradação da qualidade estrutural.

\section{Inteligência Artificial Generativa e LLMs}
A ascensão da Inteligência Artificial (IA) Generativa representa uma mudança de paradigma na computação. \citeonline{huang_2023} a define como ``a tecnologia mais transformadora do nosso tempo'', capaz de sintetizar conteúdo original a partir de vastos conjuntos de dados.

A base dessa revolução são os \textit{Large Language Models} (LLMs), construídos sobre a arquitetura \textit{Transformer}, introduzida por Vaswani et al. em 2017 no artigo seminal ``Attention Is All You Need''. O diferencial desta arquitetura é o mecanismo de \textbf{Autoatenção} (\textit{Self-Attention}), que permite ao modelo ponderar a importância de diferentes partes de uma sequência de entrada (como um arquivo de código) para prever a próxima sequência, capturando dependências de longo prazo que modelos anteriores não conseguiam processar.

No contexto de desenvolvimento de software, isso significa que o modelo não apenas "autocompleta" texto, mas infere intenção lógica baseada na sintaxe e semântica de milhões de repositórios públicos utilizados em seu treinamento.

\section{Ferramentas Selecionadas para o Estudo}
Este trabalho delimita seu escopo experimental ao uso do \textbf{GitHub Copilot} e do \textbf{ChatGPT}. A seleção destas ferramentas justifica-se por três fatores:

\begin{enumerate}
    \item \textbf{Maturidade e Adoção:} O GitHub Copilot é a ferramenta de \textit{AI Pair Programming} mais adotada na indústria \cite{dohmke2023seachange}, tornando os resultados representativos da prática real.
    \item \textbf{Integração de Contexto (\textit{Context Awareness}):} Diferente de modelos puramente baseados em chat, o Copilot integra-se ao IDE (VS Code), acessando o contexto do \textit{workspace}. Isso é crucial para tarefas de refatoração que dependem de múltiplos arquivos.
    \item \textbf{Benchmark Acadêmico:} O GPT-4 (motor do ChatGPT) permanece como a referência (\textit{baseline}) em estudos comparativos de raciocínio e geração de código \cite{li2024gptcognition}.
\end{enumerate}

\subsection{GitHub Copilot: O Programador em Par}
O Copilot atua na micro-implementação. Estudos como os de \citeonline{peng2023copilot} demonstram que sua principal contribuição é a redução da carga cognitiva em tarefas repetitivas (\textit{boilerplate}), permitindo que o desenvolvedor foque na lógica de negócio.

\subsection{ChatGPT: O Arquiteto Auxiliar}
O ChatGPT é utilizado neste estudo para tarefas de nível superior, como discussões sobre \textit{Design Patterns}, geração de cenários de teste e análise crítica de arquitetura, atuando como um parceiro de dialética técnica.

\section{Métricas de Qualidade de Software}
\label{sec:metricas_teoria}
A avaliação da qualidade do código gerado por IA exige critérios objetivos. Este estudo selecionou métricas de análise estática consolidadas na engenharia de software para mensurar Manutenibilidade, Compreensibilidade e Confiabilidade.

\subsection{Complexidade Ciclomática (McCabe)}
Proposta originalmente por \citeonline{mccabe1976complexity}, a Complexidade Ciclomática mede o número de caminhos linearmente independentes através do código fonte. Matematicamente, ela representa a complexidade estrutural de um módulo baseada em seu grafo de fluxo de controle.

A escolha desta métrica justifica-se pela sua forte correlação com a densidade de defeitos. Conforme estabelecido por McCabe, funções com complexidade superior a 10 apresentam risco estatisticamente maior de conter bugs e são consideravelmente mais difíceis de testar. No contexto de IA, monitorar esta métrica é vital para evitar que os modelos gerem soluções "espaguete" que, embora funcionais, sejam inmanuteníveis.

\subsection{Complexidade Cognitiva}
Enquanto a métrica de McCabe foca na estrutura matemática, a Complexidade Cognitiva, desenvolvida pela \citeonline{sonarqubemetrics}, visa medir o esforço mental necessário para que um desenvolvedor humano compreenda o fluxo de controle.

Esta métrica é particularmente relevante para este trabalho. Um dos riscos da IA é gerar código sintaticamente correto, mas semanticamente obscuro. A Complexidade Cognitiva penaliza estruturas que quebram o fluxo linear de leitura (como aninhamentos profundos e sequências de \textit{breaks/continues}), servindo como um indicador de legibilidade humana.

\subsection{Dívida Técnica (Technical Debt)}
O conceito de Dívida Técnica, cunhado por \citeonline{cunningham1992wycash}, é uma metáfora financeira que quantifica o custo implícito de retrabalho causado pela escolha de uma solução fácil e rápida em detrimento de uma abordagem melhor.

O SonarQube operacionaliza esse conceito estimando o tempo necessário para corrigir \textit{Code Smells} e vulnerabilidades. Monitorar essa métrica permite responder a uma pergunta central deste TCC: a velocidade da IA está sendo comprada às custas de um passivo técnico futuro?

\subsection{Cobertura de Testes e a Ilusão de Segurança}
A cobertura de testes mede a porcentagem de código executado durante testes automatizados. \citeonline{martin2008clean} alerta que, embora a alta cobertura não garanta ausência de defeitos, a baixa cobertura é garantia de problemas. Para este experimento, adota-se a premissa de que a IA deve ser capaz não apenas de gerar código produtivo, mas também os testes que garantam sua estabilidade, visando uma cobertura mínima de 90\%.

\section{Impactos da IA no Ciclo de Vida do Software}
A literatura recente converge para um debate sobre os efeitos de segunda ordem da adoção da IA.

\subsection{Produtividade vs. Qualidade}
Embora \citeonline{peng2023copilot} tenha demonstrado ganhos de velocidade de até 55\% com o uso do Copilot, estudos mais recentes apontam para o fenômeno do \textit{Code Churn} (rotatividade de código). O relatório da \citeonline{gitclear2025churn} sugere que o uso de IA pode estar aumentando a quantidade de código descartado e diminuindo a reutilização, indicando uma possível degradação na qualidade estrutural dos projetos.

\subsection{Segurança e Vulnerabilidades}
A segurança permanece como um ponto crítico. \citeonline{yetistiren2023evaluating} e \citeonline{sobania2023bugfix} destacam que LLMs tendem a reproduzir vulnerabilidades presentes em seus dados de treinamento. Isso exige uma mudança no papel do engenheiro, que passa a atuar mais como um auditor de segurança e revisor de código do que como um mero codificador, conforme corroborado por \citeonline{salvador_2024}.